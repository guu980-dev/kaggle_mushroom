{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V-oi8FxsbKdf"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Permission Warning 방지\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UyPRYQyQbVL1",
        "outputId": "fe30df3d-87b8-402a-b63b-e07ef0d5d869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading playground-series-s4e8.zip to /content\n",
            " 97% 80.0M/82.3M [00:04<00:00, 23.5MB/s]\n",
            "100% 82.3M/82.3M [00:04<00:00, 17.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c playground-series-s4e8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj7f_bG8dzw2",
        "outputId": "472d9608-35c0-41bf-bd41-5e3a22266e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/playground-series-s4e8.zip\n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/playground-series-s4e8.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnBcfZdiwXG_",
        "outputId": "fae3471b-f618-405f-f21d-2d79d0445290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ray==2.10.0\n",
            "  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (3.15.4)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (1.0.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (24.1)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (3.20.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray==2.10.0) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray==2.10.0) (0.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray==2.10.0) (2024.7.4)\n",
            "Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.10.0\n",
            "Collecting autogluon.tabular\n",
            "  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (1.26.4)\n",
            "Collecting scipy<1.13,>=1.5.4 (from autogluon.tabular)\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (2.1.4)\n",
            "Requirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (1.3.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular) (3.3)\n",
            "Collecting autogluon.core==1.1.1 (from autogluon.tabular)\n",
            "  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting autogluon.features==1.1.1 (from autogluon.tabular)\n",
            "  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular) (4.66.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular) (2.32.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.tabular) (3.7.1)\n",
            "Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading boto3-1.35.9-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular) (5.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.tabular) (71.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.tabular) (3.5.0)\n",
            "Collecting botocore<1.36.0,>=1.35.9 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading botocore-1.35.9-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.tabular)\n",
            "  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0,>=2.0.0->autogluon.tabular) (1.16.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.tabular) (3.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.tabular) (2024.7.4)\n",
            "Downloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.1/312.1 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/63.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.6/64.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.35.9-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.35.9-py3-none-any.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.7/82.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scipy, jmespath, botocore, s3transfer, boto3, autogluon.common, autogluon.features, autogluon.core, autogluon.tabular\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.tabular-1.1.1 boto3-1.35.9 botocore-1.35.9 jmespath-1.0.1 s3transfer-0.10.2 scipy-1.12.0\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (7.7.1)\n",
            "Collecting ipywidgets\n",
            "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting comm>=0.1.3 (from ipywidgets)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.7.1)\n",
            "Collecting widgetsnbextension~=4.0.12 (from ipywidgets)\n",
            "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.13)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=6.1.0->ipywidgets)\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
            "Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: widgetsnbextension, jedi, comm, ipywidgets\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.8\n",
            "    Uninstalling widgetsnbextension-3.6.8:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.8\n",
            "  Attempting uninstall: ipywidgets\n",
            "    Found existing installation: ipywidgets 7.7.1\n",
            "    Uninstalling ipywidgets-7.7.1:\n",
            "      Successfully uninstalled ipywidgets-7.7.1\n",
            "Successfully installed comm-0.2.2 ipywidgets-8.1.5 jedi-0.19.1 widgetsnbextension-4.0.13\n"
          ]
        }
      ],
      "source": [
        "!pip install ray==2.10.0\n",
        "!pip install autogluon.tabular\n",
        "!pip install -U ipywidgets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EIZfojeOwXHE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from autogluon.tabular import TabularDataset, TabularPredictor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0Bbs-4FFhiLE"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"/content/train.csv\", index_col='id')\n",
        "orig_df = pd.read_csv(\"/content/secondary_data.csv\", sep=\";\")\n",
        "test_df = pd.read_csv(\"/content/test.csv\", index_col='id')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zpNyntvYhiLG"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([train_df, orig_df], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9j9pBDCG3oI",
        "outputId": "2c5a4bef-958a-43b7-80f4-80cc44f6a8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: lightgbm 4.4.0\n",
            "Uninstalling lightgbm-4.4.0:\n",
            "  Successfully uninstalled lightgbm-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall lightgbm -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-WX-c9YuIAc0"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /etc/OpenCL/vendors && echo \"libnvidia-opencl.so.1\" > /etc/OpenCL/vendors/nvidia.icd\n",
        "# https://www.kaggle.com/code/kirankunapuli/ieee-fraud-lightgbm-with-gpu/notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "w_M-MV-zHGiw"
      },
      "outputs": [],
      "source": [
        "# !pip install lightgbm --install-option=--gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xxVlkXnjG4Jz"
      },
      "outputs": [],
      "source": [
        "# !pip install dask[dataframe]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlzHtTXtJYN4",
        "outputId": "81cbc956-17b0-4069-fd1a-a27f2dc64658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightgbm[dask]\n",
            "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm[dask]) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm[dask]) (1.12.0)\n",
            "Requirement already satisfied: dask>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2024.7.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm[dask]) (2.1.4)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2.2.1)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (24.1)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (8.4.0)\n",
            "Requirement already satisfied: distributed==2024.7.1 in /usr/local/lib/python3.10/dist-packages (from dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2024.7.1)\n",
            "Collecting dask-expr<1.2,>=1.1 (from dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask])\n",
            "  Downloading dask_expr-1.1.11-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (3.1.4)\n",
            "Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (1.0.0)\n",
            "Requirement already satisfied: msgpack>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (1.0.8)\n",
            "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (5.9.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2.4.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (3.0.0)\n",
            "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (6.3.3)\n",
            "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2.0.7)\n",
            "Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (3.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->lightgbm[dask]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->lightgbm[dask]) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->lightgbm[dask]) (2024.1)\n",
            "INFO: pip is looking at multiple versions of dask-expr to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask_expr-1.1.10-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading dask_expr-1.1.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyarrow>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (14.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask>=2.0.0->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (3.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->lightgbm[dask]) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.7.1->dask[array,dataframe,distributed]>=2.0.0; extra == \"dask\"->lightgbm[dask]) (2.1.5)\n",
            "Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dask_expr-1.1.9-py3-none-any.whl (241 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lightgbm, dask-expr\n",
            "Successfully installed dask-expr-1.1.9 lightgbm-4.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install 'lightgbm[dask]'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQLzkHziwXHG",
        "outputId": "68ba13b3-42cc-41cf-ae99-10cd89245fe3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No path specified. Models will be saved in: \"AutogluonModels/ag-20240830_193001\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.1.1\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       10.34 GB / 12.67 GB (81.6%)\n",
            "Disk Space Avail:   167.55 GB / 201.23 GB (83.3%)\n",
            "===================================================\n",
            "Presets specified: ['best_quality']\n",
            "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
            "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
            "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
            "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
            "\tRunning DyStack for up to 9000s of the 36000s of remaining time (25%).\n",
            "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
            "2024-08-30 19:30:08,923\tINFO worker.py:1752 -- Started a local Ray instance.\n",
            "\t\tContext path: \"AutogluonModels/ag-20240830_193001/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Running DyStack sub-fit ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Beginning AutoGluon training ... Time limit = 8989s\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m AutoGluon will save models to \"AutogluonModels/ag-20240830_193001/ds_sub_fit/sub_fit_ho\"\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Train Data Rows:    2824901\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Train Data Columns: 20\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Label Column:       class\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Problem Type:       binary\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Preprocessing data ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Using Feature Generators to preprocess the data ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tAvailable Memory:                    10022.19 MB\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTrain Data (Original)  Memory Usage: 2364.44 MB (23.6% of available memory)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tWarning: Data size prior to feature transformation consumes 23.6% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tStage 1 Generators:\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tStage 2 Generators:\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tStage 3 Generators:\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tStage 4 Generators:\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tStage 5 Generators:\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t39.2s = Fit runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t20 features in original data used to generate 20 features in processed data.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTrain Data (Processed) Memory Usage: 110.46 MB (1.1% of available memory)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Data preprocessing and feature engineering runtime = 45.8s ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m User-specified model hyperparameters to be fit:\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m {\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m }\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting 108 L1 models ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 5960.92s of the 8943.6s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.36% memory usage per fold, 45.43%/80.00% total).\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.36%)\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n",
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m 1 warning generated.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36m(_ray_fit pid=1915)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0353181\tvalid_set's mcc: 0.984866\n",
            "\u001b[36m(_ray_fit pid=4796)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0361311\tvalid_set's mcc: 0.984644\n",
            "\u001b[36m(_ray_fit pid=7647)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0356692\tvalid_set's mcc: 0.984774\n",
            "\u001b[36m(_ray_fit pid=10585)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0353179\tvalid_set's mcc: 0.984965\n",
            "\u001b[36m(_ray_fit pid=13539)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0361859\tvalid_set's mcc: 0.984374\n",
            "\u001b[36m(_ray_fit pid=16513)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0365451\tvalid_set's mcc: 0.984484\n",
            "\u001b[36m(_ray_fit pid=19471)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.03622\tvalid_set's mcc: 0.984565\n",
            "\u001b[36m(_ray_fit pid=22405)\u001b[0m [1000]\tvalid_set's binary_logloss: 0.0362199\tvalid_set's mcc: 0.984511\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.9849\t = Validation score   (mcc)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t5415.15s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t699.84s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 448.92s of the 3431.6s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.85% memory usage per fold, 47.42%/80.00% total).\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.85%)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.9737\t = Validation score   (mcc)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t415.6s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t27.39s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 23.57s of the 3006.24s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tWarning: Model is expected to require 1799.8s to train, which exceeds the maximum time limit of 23.6s, skipping model...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 596.09s of the 2980.69s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.9849\t = Validation score   (mcc)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t8.26s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.49s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting 108 L2 models ...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 2971.78s of the 2971.62s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.25% memory usage per fold, 57.00%/80.00% total).\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.25%)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.9841\t = Validation score   (mcc)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t2363.04s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t260.13s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 565.73s of the 565.55s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 14.29% memory usage per fold, 57.17%/80.00% total).\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=14.29%)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.9846\t = Validation score   (mcc)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t228.45s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t3.59s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 330.44s of the 330.28s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tWarning: Reducing model 'n_estimators' from 300 -> 41 due to low time. Expected time usage reduced from 2368.2s -> 330.4s...\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tNot enough time to generate out-of-fold predictions for model. Estimated time required was 157.68s compared to 101.94s of available time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tTime limit exceeded... Skipping RandomForestGini_BAG_L2.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 360.0s of the 0.64s of remaining time.\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'LightGBM_BAG_L2': 0.2}\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.9849\t = Validation score   (mcc)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t14.14s\t = Training   runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m \t0.5s\t = Validation runtime\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m AutoGluon training complete, total runtime = 9003.94s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 504.5 rows/s (353113 batch size)\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240830_193001/ds_sub_fit/sub_fit_ho\")\n",
            "\u001b[36m(_dystack pid=1250)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
            "Leaderboard on holdout data (DyStack):\n",
            "                 model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val     fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0  WeightedEnsemble_L3       0.985363   0.984902         mcc      490.186719     731.320380  6073.336291                 0.010107                0.498101          14.135982            3       True          6\n",
            "1    LightGBMXT_BAG_L1       0.985318   0.984925         mcc      465.012692     699.836752  5415.149582               465.012692              699.836752        5415.149582            1       True          1\n",
            "2  WeightedEnsemble_L2       0.985318   0.984925         mcc      465.017370     700.326558  5423.413832                 0.004678                0.489805           8.264250            2       True          3\n",
            "3      LightGBM_BAG_L2       0.985240   0.984572         mcc      490.176613     730.822279  6059.200309                 4.608255                3.592152         228.447616            2       True          5\n",
            "4    LightGBMXT_BAG_L2       0.985095   0.984125         mcc      660.858114     987.357784  8193.794914               175.289757              260.127657        2363.042222            2       True          4\n",
            "5      LightGBM_BAG_L1       0.974653   0.973743         mcc       20.555665      27.393375   415.603111                20.555665               27.393375         415.603111            1       True          2\n",
            "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
            "\t9711s\t = DyStack   runtime |\t26289s\t = Remaining runtime\n",
            "Starting main fit with num_stack_levels=1.\n",
            "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
            "Beginning AutoGluon training ... Time limit = 26289s\n",
            "AutoGluon will save models to \"AutogluonModels/ag-20240830_193001\"\n",
            "Train Data Rows:    3178014\n",
            "Train Data Columns: 20\n",
            "Label Column:       class\n",
            "Problem Type:       binary\n",
            "Preprocessing data ...\n",
            "Selected class <--> label mapping:  class 1 = p, class 0 = e\n",
            "\tNote: For your binary classification, AutoGluon arbitrarily selected which label-value represents positive (p) vs negative (e) class.\n",
            "\tTo explicitly set the positive_class, either rename classes to 1 and 0, or specify positive_class in Predictor init.\n",
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    11230.72 MB\n",
            "\tTrain Data (Original)  Memory Usage: 2659.86 MB (23.7% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 23.7% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('float', [])  :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "\t\t('object', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
            "\t\t('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "\t31.2s = Fit runtime\n",
            "\t20 features in original data used to generate 20 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 124.27 MB (1.1% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 35.25s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'mcc'\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
            "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
            "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
            "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
            "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 108 L1 models ...\n",
            "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 17497.8s of the 26253.23s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=8.88%)\n",
            "\t0.9851\t = Validation score   (mcc)\n",
            "\t13493.4s\t = Training   runtime\n",
            "\t1543.15s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L1 ... Training model for up to 3839.64s of the 12595.07s of remaining time.\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=8.95%)\n",
            "\t0.9844\t = Validation score   (mcc)\n",
            "\t3493.85s\t = Training   runtime\n",
            "\t434.87s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 285.83s of the 9041.26s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 44 due to low time. Expected time usage reduced from 1932.1s -> 285.8s...\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 203.6s compared to 99.97s of available time.\n",
            "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
            "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 13.28s of the 8768.71s of remaining time.\n",
            "\tWarning: Model is expected to require 1805.4s to train, which exceeds the maximum time limit of 13.3s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
            "Fitting model: WeightedEnsemble_L2 ... Training model for up to 1749.78s of the 8742.97s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 1.0}\n",
            "\t0.9851\t = Validation score   (mcc)\n",
            "\t8.35s\t = Training   runtime\n",
            "\t0.51s\t = Validation runtime\n",
            "Excluded models: ['KNN'] (Specified by `excluded_model_types`)\n",
            "Fitting 108 L2 models ...\n",
            "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 8733.96s of the 8733.79s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.23% memory usage per fold, 44.93%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.23%)\n",
            "\t0.9843\t = Validation score   (mcc)\n",
            "\t3261.19s\t = Training   runtime\n",
            "\t309.56s\t = Validation runtime\n",
            "Fitting model: LightGBM_BAG_L2 ... Training model for up to 5389.1s of the 5388.93s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 11.09% memory usage per fold, 44.37%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=11.09%)\n",
            "\t0.9849\t = Validation score   (mcc)\n",
            "\t479.24s\t = Training   runtime\n",
            "\t9.31s\t = Validation runtime\n",
            "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 4902.71s of the 4902.52s of remaining time.\n",
            "\t0.9851\t = Validation score   (mcc)\n",
            "\t2267.97s\t = Training   runtime\n",
            "\t146.84s\t = Validation runtime\n",
            "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 2477.67s of the 2477.5s of remaining time.\n",
            "\tWarning: Reducing model 'n_estimators' from 300 -> 286 due to low time. Expected time usage reduced from 2594.8s -> 2477.7s...\n",
            "\tNot enough time to generate out-of-fold predictions for model. Estimated time required was 1724.71s compared to 846.95s of available time.\n",
            "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L2.\n",
            "Fitting model: CatBoost_BAG_L2 ... Training model for up to 101.96s of the 101.79s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 12.32% memory usage per fold, 49.27%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=12.32%)\n",
            "\tWarning: Exception caused CatBoost_BAG_L2 to fail during training (ImportError)... Skipping this model.\n",
            "\t\t\u001b[36mray::_ray_fit()\u001b[39m (pid=157471, ip=172.28.0.12)\n",
            "ModuleNotFoundError: No module named 'catboost'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "\u001b[36mray::_ray_fit()\u001b[39m (pid=157471, ip=172.28.0.12)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/ensemble/fold_fitting_strategy.py\", line 402, in _ray_fit\n",
            "    fold_model.fit(X=X_fold, y=y_fold, X_val=X_val_fold, y_val=y_val_fold, time_limit=time_limit_fold, **resources, **kwargs_fold)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/core/models/abstract/abstract_model.py\", line 856, in fit\n",
            "    out = self._fit(**kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/tabular/models/catboost/catboost_model.py\", line 95, in _fit\n",
            "    try_import_catboost()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/autogluon/common/utils/try_import.py\", line 70, in try_import_catboost\n",
            "    raise ImportError()\n",
            "ImportError\n",
            "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 92.7s of the 92.51s of remaining time.\n",
            "\tWarning: Model is expected to require 1051.5s to train, which exceeds the maximum time limit of 92.7s, skipping model...\n",
            "\tTime limit exceeded... Skipping ExtraTreesGini_BAG_L2.\n",
            "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 75.98s of the 75.81s of remaining time.\n",
            "\tWarning: Model is expected to require 1159.7s to train, which exceeds the maximum time limit of 76.0s, skipping model...\n",
            "\tTime limit exceeded... Skipping ExtraTreesEntr_BAG_L2.\n",
            "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 58.18s of the 58.01s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 2 folds in parallel instead (Estimated 21.20% memory usage per fold, 42.40%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=21.20%)\n",
            "\tTime limit exceeded... Skipping NeuralNetFastAI_BAG_L2.\n",
            "Fitting model: XGBoost_BAG_L2 ... Training model for up to 40.32s of the 40.15s of remaining time.\n",
            "\tMemory not enough to fit 8 folds in parallel. Will train 4 folds in parallel instead (Estimated 16.27% memory usage per fold, 65.06%/80.00% total).\n",
            "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (1.0 workers, per: cpus=1, gpus=1, memory=16.27%)\n",
            "\t0.977\t = Validation score   (mcc)\n",
            "\t399.4s\t = Training   runtime\n",
            "\t17.7s\t = Validation runtime\n",
            "Fitting model: WeightedEnsemble_L3 ... Training model for up to 873.4s of the -369.08s of remaining time.\n",
            "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.8, 'RandomForestGini_BAG_L2': 0.2}\n",
            "\t0.9851\t = Validation score   (mcc)\n",
            "\t21.53s\t = Training   runtime\n",
            "\t0.74s\t = Validation runtime\n",
            "AutoGluon training complete, total runtime = 26680.42s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 199.0 rows/s (397252 batch size)\n",
            "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20240830_193001\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "*** Summary of fit() ***\n",
            "Estimated performance of each model:\n",
            "                     model  score_val eval_metric  pred_time_val      fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
            "0      WeightedEnsemble_L3   0.985147         mcc    2125.597421  19276.758692                0.743530          21.534472            3       True          8\n",
            "1        LightGBMXT_BAG_L1   0.985133         mcc    1543.146187  13493.398151             1543.146187       13493.398151            1       True          1\n",
            "2      WeightedEnsemble_L2   0.985133         mcc    1543.653075  13501.745367                0.506888           8.347216            2       True          3\n",
            "3  RandomForestGini_BAG_L2   0.985101         mcc    2124.853891  19255.224220              146.838624        2267.973029            2       True          6\n",
            "4          LightGBM_BAG_L2   0.984851         mcc    1987.320301  17466.487742                9.305033         479.236551            2       True          5\n",
            "5          LightGBM_BAG_L1   0.984431         mcc     434.869081   3493.853040              434.869081        3493.853040            1       True          2\n",
            "6        LightGBMXT_BAG_L2   0.984268         mcc    2287.575139  20248.439867              309.559871        3261.188676            2       True          4\n",
            "7           XGBoost_BAG_L2   0.977004         mcc    1995.712477  17386.646365               17.697209         399.395174            2       True          7\n",
            "Number of models trained: 8\n",
            "Types of models trained:\n",
            "{'WeightedEnsembleModel', 'StackerEnsembleModel_RF', 'StackerEnsembleModel_XGBoost', 'StackerEnsembleModel_LGB'}\n",
            "Bagging used: True  (with 8 folds)\n",
            "Multi-layer stack-ensembling used: True  (with 3 levels)\n",
            "Feature Metadata (Processed):\n",
            "(raw dtype, special dtypes):\n",
            "('category', []) : 17 | ['cap-shape', 'cap-surface', 'cap-color', 'does-bruise-or-bleed', 'gill-attachment', ...]\n",
            "('float', [])    :  3 | ['cap-diameter', 'stem-height', 'stem-width']\n",
            "Plot summary of models saved to file: AutogluonModels/ag-20240830_193001SummaryOfModels.html\n",
            "*** End of fit() summary ***\n"
          ]
        }
      ],
      "source": [
        "predictor = TabularPredictor(label='class',\n",
        "                            eval_metric='mcc',\n",
        "                            problem_type='binary').fit(train_df,\n",
        "                                                       presets='best_quality',\n",
        "                                                        time_limit=3600*10,\n",
        "                                                       verbosity=2,\n",
        "                                                       excluded_model_types=['KNN'],\n",
        "                                                       ag_args_fit={'num_gpus': 1}\n",
        "                                                      )\n",
        "results = predictor.fit_summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wu_W2X5lwXHH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "9863fa5b-ad4d-42e3-bcbc-73806461f857"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     model  score_val eval_metric  pred_time_val  \\\n",
              "0      WeightedEnsemble_L3   0.985147         mcc    2125.597421   \n",
              "1        LightGBMXT_BAG_L1   0.985133         mcc    1543.146187   \n",
              "2      WeightedEnsemble_L2   0.985133         mcc    1543.653075   \n",
              "3  RandomForestGini_BAG_L2   0.985101         mcc    2124.853891   \n",
              "4          LightGBM_BAG_L2   0.984851         mcc    1987.320301   \n",
              "5          LightGBM_BAG_L1   0.984431         mcc     434.869081   \n",
              "6        LightGBMXT_BAG_L2   0.984268         mcc    2287.575139   \n",
              "7           XGBoost_BAG_L2   0.977004         mcc    1995.712477   \n",
              "\n",
              "       fit_time  pred_time_val_marginal  fit_time_marginal  stack_level  \\\n",
              "0  19276.758692                0.743530          21.534472            3   \n",
              "1  13493.398151             1543.146187       13493.398151            1   \n",
              "2  13501.745367                0.506888           8.347216            2   \n",
              "3  19255.224220              146.838624        2267.973029            2   \n",
              "4  17466.487742                9.305033         479.236551            2   \n",
              "5   3493.853040              434.869081        3493.853040            1   \n",
              "6  20248.439867              309.559871        3261.188676            2   \n",
              "7  17386.646365               17.697209         399.395174            2   \n",
              "\n",
              "   can_infer  fit_order  \n",
              "0       True          8  \n",
              "1       True          1  \n",
              "2       True          3  \n",
              "3       True          6  \n",
              "4       True          5  \n",
              "5       True          2  \n",
              "6       True          4  \n",
              "7       True          7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-430539b5-588d-4919-bc01-45c69e9869b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>score_val</th>\n",
              "      <th>eval_metric</th>\n",
              "      <th>pred_time_val</th>\n",
              "      <th>fit_time</th>\n",
              "      <th>pred_time_val_marginal</th>\n",
              "      <th>fit_time_marginal</th>\n",
              "      <th>stack_level</th>\n",
              "      <th>can_infer</th>\n",
              "      <th>fit_order</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>WeightedEnsemble_L3</td>\n",
              "      <td>0.985147</td>\n",
              "      <td>mcc</td>\n",
              "      <td>2125.597421</td>\n",
              "      <td>19276.758692</td>\n",
              "      <td>0.743530</td>\n",
              "      <td>21.534472</td>\n",
              "      <td>3</td>\n",
              "      <td>True</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>LightGBMXT_BAG_L1</td>\n",
              "      <td>0.985133</td>\n",
              "      <td>mcc</td>\n",
              "      <td>1543.146187</td>\n",
              "      <td>13493.398151</td>\n",
              "      <td>1543.146187</td>\n",
              "      <td>13493.398151</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>WeightedEnsemble_L2</td>\n",
              "      <td>0.985133</td>\n",
              "      <td>mcc</td>\n",
              "      <td>1543.653075</td>\n",
              "      <td>13501.745367</td>\n",
              "      <td>0.506888</td>\n",
              "      <td>8.347216</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestGini_BAG_L2</td>\n",
              "      <td>0.985101</td>\n",
              "      <td>mcc</td>\n",
              "      <td>2124.853891</td>\n",
              "      <td>19255.224220</td>\n",
              "      <td>146.838624</td>\n",
              "      <td>2267.973029</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>LightGBM_BAG_L2</td>\n",
              "      <td>0.984851</td>\n",
              "      <td>mcc</td>\n",
              "      <td>1987.320301</td>\n",
              "      <td>17466.487742</td>\n",
              "      <td>9.305033</td>\n",
              "      <td>479.236551</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>LightGBM_BAG_L1</td>\n",
              "      <td>0.984431</td>\n",
              "      <td>mcc</td>\n",
              "      <td>434.869081</td>\n",
              "      <td>3493.853040</td>\n",
              "      <td>434.869081</td>\n",
              "      <td>3493.853040</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LightGBMXT_BAG_L2</td>\n",
              "      <td>0.984268</td>\n",
              "      <td>mcc</td>\n",
              "      <td>2287.575139</td>\n",
              "      <td>20248.439867</td>\n",
              "      <td>309.559871</td>\n",
              "      <td>3261.188676</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>XGBoost_BAG_L2</td>\n",
              "      <td>0.977004</td>\n",
              "      <td>mcc</td>\n",
              "      <td>1995.712477</td>\n",
              "      <td>17386.646365</td>\n",
              "      <td>17.697209</td>\n",
              "      <td>399.395174</td>\n",
              "      <td>2</td>\n",
              "      <td>True</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-430539b5-588d-4919-bc01-45c69e9869b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-430539b5-588d-4919-bc01-45c69e9869b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-430539b5-588d-4919-bc01-45c69e9869b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-591028de-41f7-43c6-acc7-d79ed6d9e597\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-591028de-41f7-43c6-acc7-d79ed6d9e597')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-591028de-41f7-43c6-acc7-d79ed6d9e597 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"predictor\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"model\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"LightGBMXT_BAG_L1\",\n          \"LightGBM_BAG_L1\",\n          \"WeightedEnsemble_L3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.002800911856603087,\n        \"min\": 0.9770036288753225,\n        \"max\": 0.9851468561051586,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.9851468561051586,\n          0.9851328933159913,\n          0.9842683550756751\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eval_metric\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"mcc\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 597.8509276858172,\n        \"min\": 434.86908054351807,\n        \"max\": 2287.5751390457153,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1543.1461870670319\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5483.806874415374,\n        \"min\": 3493.853039741516,\n        \"max\": 20248.43986749649,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          13493.398151397705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred_time_val_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 525.0999922782925,\n        \"min\": 0.506887674331665,\n        \"max\": 1543.1461870670319,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1543.1461870670319\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_time_marginal\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4501.692967093942,\n        \"min\": 8.3472158908844,\n        \"max\": 13493.398151397705,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          13493.398151397705\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stack_level\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"can_infer\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"fit_order\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "predictor.leaderboard()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kSfb0ypJwXHI"
      },
      "outputs": [],
      "source": [
        "y_pred = predictor.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bns_hWefwXHJ"
      },
      "outputs": [],
      "source": [
        "sub = pd.read_csv('/content/sample_submission.csv')\n",
        "sub['class'] = y_pred.to_list()\n",
        "sub.to_csv('submission_secondary_dataset_v2.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/submission_secondary_dataset.csv')"
      ],
      "metadata": {
        "id": "FlO4EcKlcgyx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"열의 개수: {len(df.columns)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83mDRQ4ecZIh",
        "outputId": "7695e7a7-3410-46f4-b215-65cb65129dd7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "열의 개수: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"행의 개수: {len(df)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edyX_AnfcrMI",
        "outputId": "9c4ad126-14f1-4d19-8591-b55c8fb9f8eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "행의 개수: 2077964\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 9045607,
          "sourceId": 76727,
          "sourceType": "competition"
        },
        {
          "sourceId": 194483861,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}