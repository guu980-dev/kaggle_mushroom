{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy.stats import mode\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/playground-series-s4e8/train.csv\", index_col='id')\n",
    "orig_df = pd.read_csv(\"data/secondary-mushroom-dataset-data-set/MushroomDataset/secondary_data.csv\", sep=\";\")\n",
    "test_df = pd.read_csv(\"data/playground-series-s4e8/test.csv\", index_col='id')\n",
    "train_df = pd.concat([train_df, orig_df], ignore_index=True) # Combine the competition data with the secondary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Categorize Features\n",
    "target = 'class'\n",
    "features = train_df.drop(target, axis=1).columns.to_list()\n",
    "features_with_high_null_values = [feature for feature in features if (train_df[feature].isna().sum()/len(train_df)*100)>20]\n",
    "categorical_features = train_df[features].select_dtypes(include='object').columns.to_list()\n",
    "numerical_features = list(set(features) - set(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Impute Missing Values (Null Values) '''\n",
    "\n",
    "# Clean Categorical Features\n",
    "def cleaner(df):\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        df.loc[df[col].value_counts(dropna=False)[df[col]].values < 100, col] = \"noise\"\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = cleaner(train_df)\n",
    "test_df = cleaner(test_df)\n",
    "\n",
    "# Clean Numerical Features with mean\n",
    "cap_diameter_mean = pd.concat([train_df['cap-diameter'], test_df['cap-diameter']]).mean(numeric_only=True)\n",
    "train_df['cap-diameter'].fillna(cap_diameter_mean, inplace=True)\n",
    "test_df['cap-diameter'].fillna(cap_diameter_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.copy()\n",
    "y = X.pop(target)\n",
    "\n",
    "lab_enc = LabelEncoder().fit(y)\n",
    "y = lab_enc.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(estimator, X, y, cv=5):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"    Model: {estimator.__class__.__name__}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=1/cv, shuffle=True, stratify=y, random_state=42)\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    print(f\"F1 Score : {f1.mean():.6f}\")\n",
    "    print(f\"MCC Score: {mcc.mean():.6f}\")\n",
    "    \n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(model, X, y, n_splits=5, random_state=42):\n",
    "    skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    oof_probs, oof_mccs = [], []\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training {model.__class__.__name__}\")\n",
    "    print(\"=\"*80, end=\"\\n\")\n",
    "    for fold, (train_idx, test_idx) in enumerate(skfold.split(X, y)):\n",
    "        X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "        X_test, y_test = X.iloc[test_idx, :], y[test_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        mcc = matthews_corrcoef(y_pred, y_test)\n",
    "        oof_mccs.append(mcc)\n",
    "        oof_probs.append(model.predict_proba(test_df))\n",
    "        print(f\"--- Fold {fold+1} MCC Score: {mcc:.6f}\")\n",
    "    print(f\"\\n---> Mean MCC Score: {np.mean(oof_mccs):.6f} \\xb1 {np.std(oof_mccs):.6f}\\n\\n\")\n",
    "    return oof_probs, oof_mccs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = XGBClassifier(enable_categorical=True, device=\"cuda\", tree_method=\"hist\")\n",
    "cat_clf = CatBoostClassifier(\n",
    "    cat_features=categorical_features,\n",
    "    verbose=False,\n",
    "    allow_writing_files=False,\n",
    "    task_type=\"GPU\"\n",
    ")\n",
    "lgb_clf = LGBMClassifier(device='gpu', verbosity=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 2407,\n",
    "    'eta': 0.009462133032592785,\n",
    "    'gamma': 0.2865859948765318,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 47,\n",
    "    'subsample': 0.6956431754146083,\n",
    "    'colsample_bytree': 0.3670732604094118,\n",
    "    'grow_policy': 'lossguide',\n",
    "    'max_leaves': 73,\n",
    "    'enable_categorical': True,\n",
    "    'n_jobs': -1,\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist'\n",
    "} # 0.9844272567086021\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1041,\n",
    "    'learning_rate': 0.08777255350163136,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.1259643500248322,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'random_strength': 4.276181166674371e-08,\n",
    "    'bagging_temperature': 0.35995482350907326,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 39,\n",
    "    \"verbose\": False,\n",
    "    \"allow_writing_files\": False,\n",
    "    \"task_type\": 'GPU',\n",
    "    \"cat_features\": categorical_features\n",
    "} # 0.9841773055825763\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': 2500,\n",
    "    'random_state':42,\n",
    "    'max_bin':1024,\n",
    "    'colsample_bytree':0.6,\n",
    "    'reg_lambda': 80,\n",
    "#     'device': 'gpu',\n",
    "    'verbosity': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_probs = {}\n",
    "# oof_probs['xgb'], _ = model_trainer(XGBClassifier(**xgb_params), X, y, random_state=101)\n",
    "# oof_probs['cat'], _ = model_trainer(CatBoostClassifier(**cat_params), X, y, random_state=101)\n",
    "oof_probs['lgb'], _ = model_trainer(LGBMClassifier(**lgb_params), X, y, random_state=101)\n",
    "\n",
    "oof_preds = {}\n",
    "for model in oof_probs.keys():\n",
    "    oof_preds[model] = np.argmax(np.mean(oof_probs[model], axis=0), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"/data/playground-series-s4e8/sample_submission.csv\")\n",
    "preds = [pred for model, pred in oof_preds.items()]\n",
    "md = mode(preds, axis=0)[0] if len(preds)>1 else preds[0]\n",
    "sub[target] = lab_enc.inverse_transform(md)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext1 = pd.read_csv(\"/kaggle/input/mario-s-nightmare-15-th-place-solution/submission.csv\")[target].ravel()\n",
    "# ext2 = pd.read_csv(\"/kaggle/input/ps4e8-binary-class-mathews-correlation-coeff/submission.csv\")[target].ravel()\n",
    "# ext3 = pd.read_csv(\"/kaggle/input/playgrounds4e08-modeblend/submission.csv\")[target].ravel()\n",
    "# ext4 = pd.read_csv(\"/kaggle/input/autogloun-t8-dslanders/submission.csv\")[target].ravel()\n",
    "# ext5 = pd.read_csv(\"/kaggle/input/mario-s-nightmare-denselight-0-990/submission_test7.csv\")[target].ravel()\n",
    "\n",
    "# preds = [ext1, ext2, ext3, ext4, ext5]\n",
    "# preds = [lab_enc.transform(x) for x in preds]\n",
    "# md = mode(preds, axis=0)[0]\n",
    "# sub[target] = lab_enc.inverse_transform(md)\n",
    "# sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
