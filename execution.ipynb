{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-29 16:03:42.888025: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-29 16:03:43.106092: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-29 16:03:43.194803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-29 16:03:43.214536: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-29 16:03:43.335544: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-29 16:03:44.068438: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score, cross_validate\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from scipy.stats import mode\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from tensorflow import keras\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#   project='kaggle_mushroom',\n",
    "#   config={\n",
    "#     \"learning_rate\": 0.02,\n",
    "#     \"architecture\": \"CNN\",\n",
    "#     \"dataset\": \"CIFAR-100\",\n",
    "#     \"epochs\": 10,\n",
    "#   }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"data/playground-series-s4e8/train.csv\", index_col='id')\n",
    "orig_df = pd.read_csv(\"data/secondary-mushroom-dataset-data-set/MushroomDataset/secondary_data.csv\", sep=\";\")\n",
    "test_df = pd.read_csv(\"data/playground-series-s4e8/test.csv\", index_col='id')\n",
    "train_df = pd.concat([train_df, orig_df], ignore_index=True) # Combine the competition data with the secondary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Duplicates\n",
    "train_df.drop_duplicates(inplace=True)\n",
    "\n",
    "# Categorize Features\n",
    "target = 'class'\n",
    "features = train_df.drop(target, axis=1).columns.to_list()\n",
    "features_with_high_null_values = [feature for feature in features if (train_df[feature].isna().sum()/len(train_df)*100)>20]\n",
    "categorical_features = train_df[features].select_dtypes(include='object').columns.to_list()\n",
    "numerical_features = list(set(features) - set(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Impute Missing Values (Null Values) '''\n",
    "\n",
    "# Clean Categorical Features\n",
    "def cleaner(df):\n",
    "    for col in categorical_features:\n",
    "        df[col] = df[col].fillna('missing')\n",
    "        df.loc[df[col].value_counts(dropna=False)[df[col]].values < 100, col] = \"noise\"\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    return df\n",
    "\n",
    "train_df = cleaner(train_df)\n",
    "test_df = cleaner(test_df)\n",
    "\n",
    "# Clean Numerical Features with mean\n",
    "cap_diameter_mean = pd.concat([train_df['cap-diameter'], test_df['cap-diameter']]).mean(numeric_only=True)\n",
    "train_df['cap-diameter'].fillna(cap_diameter_mean, inplace=True)\n",
    "test_df['cap-diameter'].fillna(cap_diameter_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.copy()\n",
    "y = X.pop(target)\n",
    "\n",
    "lab_enc = LabelEncoder().fit(y)\n",
    "y = lab_enc.transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_report(estimator, X, y, cv=5):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"    Model: {estimator.__class__.__name__}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=1/cv, shuffle=True, stratify=y, random_state=42)\n",
    "    \n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    mcc = matthews_corrcoef(y_test, y_pred)\n",
    "    print(f\"F1 Score : {f1.mean():.6f}\")\n",
    "    print(f\"MCC Score: {mcc.mean():.6f}\")\n",
    "    \n",
    "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_trainer(model, X, y, test_set, skfold):\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Training {model.__class__.__name__}\")\n",
    "    print(\"=\"*80, end=\"\\n\")\n",
    "\n",
    "    oof_mccs = []\n",
    "    test_probs = np.zeros((test_set.shape[0],))   # test set probabilities. Average of each fold's probability prediction on test set.\n",
    "    oof_probs = np.zeros((X.shape[0],))   # training set probabilities\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skfold.split(X, y)):\n",
    "        # Select train, validation set by each fold\n",
    "        X_train, y_train = X.iloc[train_idx, :], y[train_idx]\n",
    "        X_val, y_val = X.iloc[val_idx, :], y[val_idx]\n",
    "\n",
    "        # Train Model\n",
    "        model = clone(model)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate by validation set\n",
    "        val_probs = model.predict_proba(X_val)[:, 1]   # Calculate probability\n",
    "        oof_probs[val_idx] = val_probs   # Save probability of this fold's validation set\n",
    "        val_preds = (val_probs > 0.5).astype(int)   # Convert probability to label\n",
    "        mcc = matthews_corrcoef(y_val, val_preds)   # Calculate mcc score\n",
    "        oof_mccs.append(mcc)   # Save mcc score of this fold's validation set\n",
    "        print(f\"--- Fold {fold+1} MCC Score: {mcc:.6f}\")\n",
    "\n",
    "        # Predict on test set\n",
    "        test_probs += model.predict_proba(test_set)[:, 1] / skfold.get_n_splits()   # Aggregate test set probabilities\n",
    "\n",
    "    mean_mcc_score = np.mean(oof_mccs)\n",
    "    std_mcc_score = np.std(oof_mccs)\n",
    "    print(f\"\\n---> Mean MCC Score: {mean_mcc_score:.6f} \\xb1 {std_mcc_score:.6f}\\n\\n\")\n",
    "    \n",
    "    total_mcc_score = matthews_corrcoef(y, (oof_probs > 0.5).astype(int))\n",
    "    print(f\"Total MCC Score: {total_mcc_score:.6f}\")\n",
    "\n",
    "    return oof_mccs, test_probs, oof_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' tree-based models '''\n",
    "\n",
    "xgb_clf = XGBClassifier(enable_categorical=True, device=\"cuda\", tree_method=\"hist\")\n",
    "cat_clf = CatBoostClassifier(\n",
    "    cat_features=categorical_features,\n",
    "    verbose=False,\n",
    "    allow_writing_files=False,\n",
    "    task_type=\"GPU\"\n",
    ")\n",
    "lgb_clf = LGBMClassifier(device='gpu', verbosity=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1724915040.929438    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.040894    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.043381    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.048605    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.050631    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.052508    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.133255    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.134194    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1724915041.134978    5766 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-29 16:04:01.136283: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9633 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Neural Network models '''\n",
    "\n",
    "# Neural network (Keras) with two hidden layers (one-hot encoded)\n",
    "def get_model(meta):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Input(meta[\"X_shape_\"][1:]))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(64, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "display(keras.utils.plot_model(get_model({\"X_shape_\": X.shape}),\n",
    "                       show_shapes=True, show_layer_activations=True, dpi=80))\n",
    "\n",
    "\n",
    "nn_clf = KerasClassifier(\n",
    "    get_model,\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=keras.optimizers.AdamW(learning_rate=0.01),\n",
    "    validation_split=0.03,\n",
    "    batch_size=8192,\n",
    "    validation_batch_size=65536,\n",
    "    epochs=53,\n",
    "    # verbose=0, # or 2\n",
    "    callbacks=[keras.callbacks.ReduceLROnPlateau(patience=3),\n",
    "               keras.callbacks.EarlyStopping(patience=5, min_delta=0.00003)]\n",
    ")\n",
    "\n",
    "nn_model = make_pipeline(ColumnTransformer([\n",
    "                                        ('float', make_pipeline(PowerTransformer(),\n",
    "                                                                 SimpleImputer(add_indicator=True)),\n",
    "                                          numerical_features),\n",
    "                                         ('cat', OneHotEncoder(drop='first',\n",
    "                                                               sparse_output=False,\n",
    "                                                               dtype=np.float32,\n",
    "                                                               handle_unknown='infrequent_if_exist',\n",
    "                                                               min_frequency=50),\n",
    "                                          categorical_features),\n",
    "                                        ]),\n",
    "                      StandardScaler(),\n",
    "                      BaggingClassifier(nn_clf, n_estimators=7, bootstrap=False))\n",
    "# cross_validate(nn_model, 'Keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyper Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': 2407,\n",
    "    'eta': 0.009462133032592785,\n",
    "    'gamma': 0.2865859948765318,\n",
    "    'max_depth': 31,\n",
    "    'min_child_weight': 47,\n",
    "    'subsample': 0.6956431754146083,\n",
    "    'colsample_bytree': 0.3670732604094118,\n",
    "    'grow_policy': 'lossguide',\n",
    "    'max_leaves': 73,\n",
    "    'enable_categorical': True,\n",
    "    'n_jobs': -1,\n",
    "    'device': 'cuda',\n",
    "    'tree_method': 'hist'\n",
    "} # 0.9844272567086021\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 1041,\n",
    "    'learning_rate': 0.08777255350163136,\n",
    "    'depth': 10,\n",
    "    'l2_leaf_reg': 0.1259643500248322,\n",
    "    'bootstrap_type': 'Bayesian',\n",
    "    'random_strength': 4.276181166674371e-08,\n",
    "    'bagging_temperature': 0.35995482350907326,\n",
    "    'od_type': 'Iter',\n",
    "    'od_wait': 39,\n",
    "    \"verbose\": False,\n",
    "    \"allow_writing_files\": False,\n",
    "    \"task_type\": 'GPU',\n",
    "    \"cat_features\": categorical_features\n",
    "} # 0.9841773055825763\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': 2500,\n",
    "    'random_state':42,\n",
    "    'max_bin':1024,\n",
    "    'colsample_bytree':0.6,\n",
    "    'reg_lambda': 80,\n",
    "    # 'device': 'gpu',\n",
    "    'verbosity': -1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% time\n",
    "# cv_summary, test_probs, oof_probs = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "cv_summary, test_probs, oof_probs = pd.read_pickle(\"result/deep_nn_test1/cv_summary.pkl\"), pd.read_pickle(\"result/deep_nn_test1/test_probs.pkl\"), pd.read_pickle(\"result/deep_nn_test1/oof_probs.pkl\")\n",
    "random_state = 101\n",
    "skfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_summary['xgb'], test_probs['xgb'], oof_probs['xgb'] = model_trainer(XGBClassifier(**xgb_params), X, y, test_df, skfold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_summary['cat'], test_probs['cat'], oof_probs['cat'] = model_trainer(CatBoostClassifier(**cat_params), X, y, test_df, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# cv_summary['lgb'], test_probs['lgb'], oof_probs['lgb'] = model_trainer(LGBMClassifier(**lgb_params), X, y, test_df, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Pipeline\n",
      "================================================================================\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1469 - val_loss: 0.0252 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0241 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0411 - val_loss: 0.0244 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0404 - val_loss: 0.0235 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0399 - val_loss: 0.0226 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0214 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0391 - val_loss: 0.0214 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0390 - val_loss: 0.0207 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0209 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0209 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0207 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0372 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1410 - val_loss: 0.0231 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0422 - val_loss: 0.0210 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0410 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0404 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0185 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0391 - val_loss: 0.0185 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0387 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0384 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.0197 - learning_rate: 0.0100\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0354 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 25/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 26/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1129 - val_loss: 0.0275 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0425 - val_loss: 0.0220 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0409 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0401 - val_loss: 0.0200 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0398 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0393 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0392 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - val_loss: 0.0191 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0373 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1284 - val_loss: 0.0210 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0411 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0399 - val_loss: 0.0189 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0378 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0377 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0366 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0349 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0346 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0346 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0168 - learning_rate: 1.0000e-05\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0168 - learning_rate: 1.0000e-06\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - val_loss: 0.0168 - learning_rate: 1.0000e-06\n",
      "Epoch 25/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - val_loss: 0.0168 - learning_rate: 1.0000e-06\n",
      "Epoch 26/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0346 - val_loss: 0.0168 - learning_rate: 1.0000e-07\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1118 - val_loss: 0.0286 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0424 - val_loss: 0.0234 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0409 - val_loss: 0.0216 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0401 - val_loss: 0.0212 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0398 - val_loss: 0.0204 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.0208 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0206 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0209 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0371 - val_loss: 0.0180 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - val_loss: 0.0182 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0182 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0183 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1332 - val_loss: 0.0261 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0431 - val_loss: 0.0248 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0411 - val_loss: 0.0236 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0405 - val_loss: 0.0234 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0401 - val_loss: 0.0228 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0225 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0395 - val_loss: 0.0219 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0223 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0219 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0216 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0221 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0384 - val_loss: 0.0223 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0383 - val_loss: 0.0224 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0177 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1318 - val_loss: 0.0211 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0415 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.0191 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0189 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0372 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0354 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "--- Fold 1 MCC Score: 0.984336\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1365 - val_loss: 0.0206 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0415 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0391 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0371 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0349 - val_loss: 0.0171 - learning_rate: 1.0000e-06\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1270 - val_loss: 0.0301 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0426 - val_loss: 0.0267 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0411 - val_loss: 0.0253 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0405 - val_loss: 0.0257 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - val_loss: 0.0231 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0399 - val_loss: 0.0224 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0205 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0393 - val_loss: 0.0207 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0208 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0193 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0384 - val_loss: 0.0193 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0382 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0369 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0179 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0181 - learning_rate: 1.0000e-03\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1266 - val_loss: 0.0211 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0420 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0408 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0353 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1370 - val_loss: 0.0236 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0419 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0401 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0386 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0380 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0369 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0173 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0173 - learning_rate: 1.0000e-06\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0173 - learning_rate: 1.0000e-06\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1126 - val_loss: 0.0211 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0398 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0189 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0374 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0170 - learning_rate: 1.0000e-05\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0170 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1294 - val_loss: 0.0211 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0405 - val_loss: 0.0200 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0398 - val_loss: 0.0191 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0198 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0371 - val_loss: 0.0180 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0179 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0179 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0359 - val_loss: 0.0179 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0358 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0356 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0349 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0347 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0347 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
      "Epoch 25/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - val_loss: 0.0174 - learning_rate: 1.0000e-05\n",
      "Epoch 26/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0174 - learning_rate: 1.0000e-06\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1306 - val_loss: 0.0224 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0202 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0403 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0393 - val_loss: 0.0193 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0384 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0382 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0376 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0375 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0374 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0349 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
      "Epoch 25/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0171 - learning_rate: 1.0000e-05\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "--- Fold 2 MCC Score: 0.984602\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1118 - val_loss: 0.0270 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0424 - val_loss: 0.0218 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0409 - val_loss: 0.0201 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0396 - val_loss: 0.0203 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0393 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0376 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0372 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0373 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0167 - learning_rate: 1.0000e-03\n",
      "Epoch 25/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0167 - learning_rate: 1.0000e-03\n",
      "Epoch 26/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0168 - learning_rate: 1.0000e-03\n",
      "Epoch 27/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 28/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0349 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 29/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1172 - val_loss: 0.0249 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0424 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0402 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0396 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0388 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0374 - val_loss: 0.0167 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - val_loss: 0.0167 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0167 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0167 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0166 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0167 - learning_rate: 1.0000e-05\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0167 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1371 - val_loss: 0.0250 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0419 - val_loss: 0.0213 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0407 - val_loss: 0.0198 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0193 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0381 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0377 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0376 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0375 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0374 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0350 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0348 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0347 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 23/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0167 - learning_rate: 1.0000e-04\n",
      "Epoch 24/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0346 - val_loss: 0.0168 - learning_rate: 1.0000e-05\n",
      "Epoch 25/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0345 - val_loss: 0.0168 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1495 - val_loss: 0.0259 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0430 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0409 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0373 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0361 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0168 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - val_loss: 0.0168 - learning_rate: 1.0000e-05\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - val_loss: 0.0169 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1203 - val_loss: 0.0207 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0398 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0372 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0175 - learning_rate: 1.0000e-05\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0175 - learning_rate: 1.0000e-06\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1523 - val_loss: 0.0201 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0413 - val_loss: 0.0179 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0402 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0172 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0373 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1391 - val_loss: 0.0226 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0412 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0400 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0394 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0380 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0379 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0352 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "--- Fold 3 MCC Score: 0.984273\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1078 - val_loss: 0.0220 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0412 - val_loss: 0.0193 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0400 - val_loss: 0.0198 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0198 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0359 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0353 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.0172 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1085 - val_loss: 0.0199 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0416 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - val_loss: 0.0185 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0397 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0189 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0373 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0365 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0169 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0170 - learning_rate: 1.0000e-05\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0170 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1238 - val_loss: 0.0203 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0421 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0396 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0170 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0167 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0168 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0167 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0168 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0373 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0170 - learning_rate: 1.0000e-04\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1259 - val_loss: 0.0258 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0421 - val_loss: 0.0220 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - val_loss: 0.0202 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0392 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0387 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0382 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0369 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1166 - val_loss: 0.0204 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0401 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0394 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0391 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0171 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0170 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0172 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0370 - val_loss: 0.0172 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0173 - learning_rate: 1.0000e-03\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1433 - val_loss: 0.0245 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0423 - val_loss: 0.0215 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0409 - val_loss: 0.0207 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0403 - val_loss: 0.0197 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0194 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0392 - val_loss: 0.0189 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0387 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0384 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0362 - val_loss: 0.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0177 - learning_rate: 1.0000e-03\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0175 - learning_rate: 1.0000e-04\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1495 - val_loss: 0.0232 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0420 - val_loss: 0.0209 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.0197 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0396 - val_loss: 0.0187 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0391 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0388 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0385 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0384 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0379 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0367 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "--- Fold 4 MCC Score: 0.984457\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1374 - val_loss: 0.0249 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0419 - val_loss: 0.0221 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - val_loss: 0.0210 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - val_loss: 0.0201 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0206 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.0204 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0389 - val_loss: 0.0205 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0375 - val_loss: 0.0183 - learning_rate: 1.0000e-03\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.0182 - learning_rate: 1.0000e-03\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - val_loss: 0.0181 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0363 - val_loss: 0.0181 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0361 - val_loss: 0.0181 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0176 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0176 - learning_rate: 1.0000e-05\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.0176 - learning_rate: 1.0000e-06\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0176 - learning_rate: 1.0000e-06\n",
      "Epoch 22/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0176 - learning_rate: 1.0000e-06\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1176 - val_loss: 0.0209 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0420 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0409 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0400 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0390 - val_loss: 0.0170 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0169 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0169 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0384 - val_loss: 0.0169 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - val_loss: 0.0170 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0370 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0361 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0169 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0355 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0171 - learning_rate: 1.0000e-04\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1258 - val_loss: 0.0207 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0419 - val_loss: 0.0197 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0407 - val_loss: 0.0192 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0399 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0395 - val_loss: 0.0189 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0392 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0386 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0364 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0360 - val_loss: 0.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0356 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0172 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0354 - val_loss: 0.0173 - learning_rate: 1.0000e-05\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1496 - val_loss: 0.0238 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0418 - val_loss: 0.0218 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0406 - val_loss: 0.0202 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.0190 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0392 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0388 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0177 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0381 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0378 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0175 - learning_rate: 1.0000e-03\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1337 - val_loss: 0.0208 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0416 - val_loss: 0.0206 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0401 - val_loss: 0.0191 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0395 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0390 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0386 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0384 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0381 - val_loss: 0.0173 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0379 - val_loss: 0.0174 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0367 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0359 - val_loss: 0.0174 - learning_rate: 1.0000e-03\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.1277 - val_loss: 0.0201 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0414 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0402 - val_loss: 0.0183 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.0180 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0390 - val_loss: 0.0181 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0178 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0385 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0383 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0382 - val_loss: 0.0175 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.0176 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0368 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0170 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0358 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0171 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.0174 - learning_rate: 1.0000e-04\n",
      "Epoch 1/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1462 - val_loss: 0.0224 - learning_rate: 0.0100\n",
      "Epoch 2/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0417 - val_loss: 0.0196 - learning_rate: 0.0100\n",
      "Epoch 3/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0405 - val_loss: 0.0195 - learning_rate: 0.0100\n",
      "Epoch 4/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0397 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 5/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0393 - val_loss: 0.0188 - learning_rate: 0.0100\n",
      "Epoch 6/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0389 - val_loss: 0.0185 - learning_rate: 0.0100\n",
      "Epoch 7/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0387 - val_loss: 0.0186 - learning_rate: 0.0100\n",
      "Epoch 8/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0385 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 9/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0383 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 10/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0382 - val_loss: 0.0184 - learning_rate: 0.0100\n",
      "Epoch 11/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0182 - learning_rate: 0.0100\n",
      "Epoch 12/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0369 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 13/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.0177 - learning_rate: 1.0000e-03\n",
      "Epoch 14/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0357 - val_loss: 0.0177 - learning_rate: 1.0000e-03\n",
      "Epoch 15/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.0178 - learning_rate: 1.0000e-03\n",
      "Epoch 16/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 17/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 18/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0352 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 19/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0177 - learning_rate: 1.0000e-04\n",
      "Epoch 20/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0351 - val_loss: 0.0177 - learning_rate: 1.0000e-05\n",
      "Epoch 21/53\n",
      "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.0177 - learning_rate: 1.0000e-05\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m78/78\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "--- Fold 5 MCC Score: 0.984542\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\u001b[1m254/254\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "---> Mean MCC Score: 0.984442 ± 0.000123\n",
      "\n",
      "\n",
      "Total MCC Score: 0.984442\n"
     ]
    }
   ],
   "source": [
    "cv_summary['nn'], test_probs['nn'], oof_probs['nn'] = model_trainer(nn_model, X, y, test_df, skfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_550f1_row0_col0, #T_550f1_row0_col1, #T_550f1_row0_col2, #T_550f1_row0_col3, #T_550f1_row0_col4, #T_550f1_row0_col5, #T_550f1_row1_col3, #T_550f1_row2_col6 {\n",
       "  background-color: #1b9e77;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_550f1_row0_col6, #T_550f1_row3_col0, #T_550f1_row3_col1, #T_550f1_row3_col2, #T_550f1_row3_col3, #T_550f1_row3_col4, #T_550f1_row3_col5 {\n",
       "  background-color: #666666;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_550f1_row1_col0, #T_550f1_row1_col1, #T_550f1_row1_col2, #T_550f1_row1_col4, #T_550f1_row1_col5, #T_550f1_row3_col6 {\n",
       "  background-color: #d95f02;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_550f1_row1_col6 {\n",
       "  background-color: #a6761d;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_550f1_row2_col0, #T_550f1_row2_col5 {\n",
       "  background-color: #e7298a;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_550f1_row2_col1, #T_550f1_row2_col3 {\n",
       "  background-color: #7570b3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_550f1_row2_col2, #T_550f1_row2_col4 {\n",
       "  background-color: #e6ab02;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_550f1\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_550f1_level0_col0\" class=\"col_heading level0 col0\" >fold1</th>\n",
       "      <th id=\"T_550f1_level0_col1\" class=\"col_heading level0 col1\" >fold2</th>\n",
       "      <th id=\"T_550f1_level0_col2\" class=\"col_heading level0 col2\" >fold3</th>\n",
       "      <th id=\"T_550f1_level0_col3\" class=\"col_heading level0 col3\" >fold4</th>\n",
       "      <th id=\"T_550f1_level0_col4\" class=\"col_heading level0 col4\" >fold5</th>\n",
       "      <th id=\"T_550f1_level0_col5\" class=\"col_heading level0 col5\" >Mean</th>\n",
       "      <th id=\"T_550f1_level0_col6\" class=\"col_heading level0 col6\" >Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_550f1_level0_row0\" class=\"row_heading level0 row0\" >lgb</th>\n",
       "      <td id=\"T_550f1_row0_col0\" class=\"data row0 col0\" >0.985025</td>\n",
       "      <td id=\"T_550f1_row0_col1\" class=\"data row0 col1\" >0.984989</td>\n",
       "      <td id=\"T_550f1_row0_col2\" class=\"data row0 col2\" >0.984879</td>\n",
       "      <td id=\"T_550f1_row0_col3\" class=\"data row0 col3\" >0.984977</td>\n",
       "      <td id=\"T_550f1_row0_col4\" class=\"data row0 col4\" >0.984971</td>\n",
       "      <td id=\"T_550f1_row0_col5\" class=\"data row0 col5\" >0.984968</td>\n",
       "      <td id=\"T_550f1_row0_col6\" class=\"data row0 col6\" >0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_550f1_level0_row1\" class=\"row_heading level0 row1\" >xgb</th>\n",
       "      <td id=\"T_550f1_row1_col0\" class=\"data row1 col0\" >0.984879</td>\n",
       "      <td id=\"T_550f1_row1_col1\" class=\"data row1 col1\" >0.984927</td>\n",
       "      <td id=\"T_550f1_row1_col2\" class=\"data row1 col2\" >0.984749</td>\n",
       "      <td id=\"T_550f1_row1_col3\" class=\"data row1 col3\" >0.984930</td>\n",
       "      <td id=\"T_550f1_row1_col4\" class=\"data row1 col4\" >0.984882</td>\n",
       "      <td id=\"T_550f1_row1_col5\" class=\"data row1 col5\" >0.984873</td>\n",
       "      <td id=\"T_550f1_row1_col6\" class=\"data row1 col6\" >0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_550f1_level0_row2\" class=\"row_heading level0 row2\" >cat</th>\n",
       "      <td id=\"T_550f1_row2_col0\" class=\"data row2 col0\" >0.984749</td>\n",
       "      <td id=\"T_550f1_row2_col1\" class=\"data row2 col1\" >0.984860</td>\n",
       "      <td id=\"T_550f1_row2_col2\" class=\"data row2 col2\" >0.984470</td>\n",
       "      <td id=\"T_550f1_row2_col3\" class=\"data row2 col3\" >0.984838</td>\n",
       "      <td id=\"T_550f1_row2_col4\" class=\"data row2 col4\" >0.984675</td>\n",
       "      <td id=\"T_550f1_row2_col5\" class=\"data row2 col5\" >0.984718</td>\n",
       "      <td id=\"T_550f1_row2_col6\" class=\"data row2 col6\" >0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_550f1_level0_row3\" class=\"row_heading level0 row3\" >nn</th>\n",
       "      <td id=\"T_550f1_row3_col0\" class=\"data row3 col0\" >0.984336</td>\n",
       "      <td id=\"T_550f1_row3_col1\" class=\"data row3 col1\" >0.984602</td>\n",
       "      <td id=\"T_550f1_row3_col2\" class=\"data row3 col2\" >0.984273</td>\n",
       "      <td id=\"T_550f1_row3_col3\" class=\"data row3 col3\" >0.984457</td>\n",
       "      <td id=\"T_550f1_row3_col4\" class=\"data row3 col4\" >0.984542</td>\n",
       "      <td id=\"T_550f1_row3_col5\" class=\"data row3 col5\" >0.984442</td>\n",
       "      <td id=\"T_550f1_row3_col6\" class=\"data row3 col6\" >0.000123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x73fb40053100>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Performance Summary for comparing model (Not Needed)\n",
    "transposed_df = cv_summary.transpose()\n",
    "transposed_df.columns = ['fold1','fold2','fold3','fold4','fold5']\n",
    "transposed_df['Mean'] = transposed_df.mean(axis=1)\n",
    "transposed_df['Std'] = transposed_df.std(axis=1)\n",
    "transposed_df.sort_values(by = 'Mean', ascending=False).style.background_gradient('Dark2_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x2000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model diversity check (Not Needed)\n",
    "sns.set(font_scale=1.1)\n",
    "correlation_train = oof_probs.corr()\n",
    "mask = np.triu(correlation_train.corr())\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_train,\n",
    "            annot=True,\n",
    "            fmt='.3f',\n",
    "            cmap='coolwarm',\n",
    "            square=True,\n",
    "            mask=mask,\n",
    "            linewidths=1,\n",
    "            cbar=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting hard & soft\n",
    "def voting_ensemble(oof_probs, y, threshold=0.5, voting_type='soft'):\n",
    "    if voting_type == 'soft':\n",
    "        ensemble_preds = oof_probs.mean(axis=1)\n",
    "        ensemble_class_preds = (ensemble_preds > threshold).astype(int)\n",
    "        \n",
    "    elif voting_type == 'hard':\n",
    "        binary_preds = (oof_probs > threshold).astype(int)\n",
    "        ensemble_class_preds = mode(binary_preds, axis=1)[0].flatten()\n",
    "    \n",
    "    mcc_score = matthews_corrcoef(y, ensemble_class_preds)\n",
    "    \n",
    "    return mcc_score, ensemble_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851856811089983\n"
     ]
    }
   ],
   "source": [
    "soft_vote_score, soft_vote_pred = voting_ensemble(oof_probs, y, voting_type='soft')\n",
    "print(soft_vote_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9850658948785984\n"
     ]
    }
   ],
   "source": [
    "hard_vote_score, hard_vote_pred = voting_ensemble(oof_probs, y, voting_type='hard')\n",
    "print(hard_vote_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting hard & soft\n",
    "def voting_ensemble_only_pred(oof_probs, threshold=0.5, voting_type='soft'):\n",
    "  if voting_type == 'soft':\n",
    "      ensemble_preds = oof_probs.mean(axis=1)\n",
    "      ensemble_class_preds = (ensemble_preds > threshold).astype(int)\n",
    "      \n",
    "  elif voting_type == 'hard':\n",
    "      binary_preds = (oof_probs > threshold).astype(int)\n",
    "      ensemble_class_preds = mode(binary_preds, axis=1)[0].flatten()\n",
    "\n",
    "  return ensemble_class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_vote_pred_test = voting_ensemble_only_pred(test_probs, voting_type='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0          0\n",
      "1          1\n",
      "2          1\n",
      "3          1\n",
      "4          0\n",
      "          ..\n",
      "2077959    1\n",
      "2077960    1\n",
      "2077961    1\n",
      "2077962    0\n",
      "2077963    0\n",
      "Length: 2077964, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(soft_vote_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for meta model                                                                                                 \n",
    "meta_model_params = {\n",
    "    'C': 0.000237302749626327,\n",
    "    'max_iter': 2500,\n",
    "    'tol': 9.996751434702547e-05,\n",
    "    'solver': 'saga',\n",
    "    'penalty': 'l1'\n",
    "}\n",
    "\n",
    "meta_model = LogisticRegression(**meta_model_params, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV score: \n",
      "0.9851403054826088\n",
      "Number of available models: 4\n",
      "Number of selected models for ensemble: 4\n",
      "Selected models: ['xgb' 'cat' 'lgb' 'nn']\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "#Deciding which models to include ensemble\n",
    "\n",
    "min_features_to_select = 1\n",
    "\n",
    "# Create a pipeline with preprocessor and RFECV\n",
    "pipeline = Pipeline([\n",
    "    ('Scaler', StandardScaler()),\n",
    "    ('rfecv', RFECV(estimator=meta_model,\n",
    "                    step=1,\n",
    "                    cv=skfold,\n",
    "                    scoring=make_scorer(matthews_corrcoef),\n",
    "                    min_features_to_select=min_features_to_select,\n",
    "                    n_jobs=-1,))\n",
    "])\n",
    "\n",
    "# Fit the pipeline on oof_preds\n",
    "pipeline.fit(oof_probs, y)\n",
    "\n",
    "#CV score\n",
    "print(\"Best CV score: \")\n",
    "selected_models = np.array(oof_probs.columns)[pipeline.named_steps['rfecv'].support_]\n",
    "print( pipeline.named_steps['rfecv'].cv_results_[\"mean_test_score\"][len(selected_models) - 1])\n",
    "\n",
    "\n",
    "# Selected models after RFECV\n",
    "print('Number of available models:', len(oof_probs.columns))\n",
    "print('Number of selected models for ensemble:', len(selected_models))\n",
    "print(\"Selected models:\", selected_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = meta_model.fit(oof_probs[selected_models], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9851447906793618\n"
     ]
    }
   ],
   "source": [
    "preds_train =  meta_model.predict(oof_probs[selected_models])\n",
    "mcc_score = matthews_corrcoef(y, preds_train)\n",
    "print(mcc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test =  meta_model.predict(test_probs[selected_models])\n",
    "preds_test = lab_enc.inverse_transform(preds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Intermediate Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_summary['lgb'], test_probs['lgb'], oof_probs['lgb']\n",
    "exp_name = \"4_layers_nn\"\n",
    "\n",
    "from pathlib import Path\n",
    "Path(f\"result/{exp_name}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "cv_summary.to_pickle(f\"result/{exp_name}/cv_summary.pkl\")\n",
    "test_probs.to_pickle(f\"result/{exp_name}/test_probs.pkl\")\n",
    "oof_probs.to_pickle(f\"result/{exp_name}/oof_probs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Stacking '''\n",
    "\n",
    "output = pd.DataFrame({'id': test_df.index,\n",
    "                       'class': preds_test})\n",
    "output.to_csv('pred/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ''' Soft Voting '''\n",
    "# soft_vote_pred_test = lab_enc.inverse_transform(soft_vote_pred_test)\n",
    "# output = pd.DataFrame({'id': test_df.index,\n",
    "#                        'class': soft_vote_pred_test})\n",
    "# output.to_csv('pred/submission_soft_vote_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #save oofs and test predictions for later usage\n",
    "# oof_probs.to_parquet('oof_predictions_v01.parquet', index=False)\n",
    "# test_probs.to_parquet('test_predictions_v01.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(\"/data/playground-series-s4e8/sample_submission.csv\")\n",
    "# preds = [pred for model, pred in oof_preds.items()]\n",
    "# md = mode(preds, axis=0)[0] if len(preds)>1 else preds[0]\n",
    "# sub[target] = lab_enc.inverse_transform(md)\n",
    "# sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext1 = pd.read_csv(\"/kaggle/input/mario-s-nightmare-15-th-place-solution/submission.csv\")[target].ravel()\n",
    "# ext2 = pd.read_csv(\"/kaggle/input/ps4e8-binary-class-mathews-correlation-coeff/submission.csv\")[target].ravel()\n",
    "# ext3 = pd.read_csv(\"/kaggle/input/playgrounds4e08-modeblend/submission.csv\")[target].ravel()\n",
    "# ext4 = pd.read_csv(\"/kaggle/input/autogloun-t8-dslanders/submission.csv\")[target].ravel()\n",
    "# ext5 = pd.read_csv(\"/kaggle/input/mario-s-nightmare-denselight-0-990/submission_test7.csv\")[target].ravel()\n",
    "\n",
    "# preds = [ext1, ext2, ext3, ext4, ext5]\n",
    "# preds = [lab_enc.transform(x) for x in preds]\n",
    "# md = mode(preds, axis=0)[0]\n",
    "# sub[target] = lab_enc.inverse_transform(md)\n",
    "# sub.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
